<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Add a new Tuner • mlr3tuning</title>
<!-- favicons --><link rel="icon" type="image/png" sizes="16x16" href="../favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="../favicon-32x32.png">
<link rel="apple-touch-icon" type="image/png" sizes="180x180" href="../apple-touch-icon.png">
<link rel="apple-touch-icon" type="image/png" sizes="120x120" href="../apple-touch-icon-120x120.png">
<link rel="apple-touch-icon" type="image/png" sizes="76x76" href="../apple-touch-icon-76x76.png">
<link rel="apple-touch-icon" type="image/png" sizes="60x60" href="../apple-touch-icon-60x60.png">
<script src="../lightswitch.js"></script><script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.3.1/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.3.1/bootstrap.bundle.min.js"></script><link href="../deps/Roboto-0.4.9/font.css" rel="stylesheet">
<link href="../deps/JetBrains_Mono-0.4.9/font.css" rel="stylesheet">
<link href="../deps/Roboto_Slab-0.4.9/font.css" rel="stylesheet">
<link href="../deps/font-awesome-6.4.2/css/all.min.css" rel="stylesheet">
<link href="../deps/font-awesome-6.4.2/css/v4-shims.min.css" rel="stylesheet">
<script src="../deps/headroom-0.11.0/headroom.min.js"></script><script src="../deps/headroom-0.11.0/jQuery.headroom.min.js"></script><script src="../deps/bootstrap-toc-1.0.1/bootstrap-toc.min.js"></script><script src="../deps/clipboard.js-2.0.11/clipboard.min.js"></script><script src="../deps/search-1.0.0/autocomplete.jquery.min.js"></script><script src="../deps/search-1.0.0/fuse.min.js"></script><script src="../deps/search-1.0.0/mark.min.js"></script><script src="../deps/MathJax-3.2.2/tex-chtml.min.js"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Add a new Tuner">
<meta name="robots" content="noindex">
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>


    <nav class="navbar navbar-expand-lg fixed-top " aria-label="Site navigation"><div class="container">

    <a class="navbar-brand me-2" href="../index.html">mlr3tuning</a>

    <small class="nav-text text-default me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="In-development version">1.0.1.9000</small>


    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item"><a class="nav-link" href="../reference/index.html"><span class="fa fa-file-alt"></span> Reference</a></li>
<li class="nav-item"><a class="nav-link" href="../news/index.html">Changelog</a></li>
<li class="nav-item"><a class="external-link nav-link" href="https://mlr3book.mlr-org.com"><span class="fa fa-link"></span> mlr3book</a></li>
      </ul>
<ul class="navbar-nav">
<li class="nav-item"><form class="form-inline" role="search">
 <input class="form-control" type="search" name="search-input" id="search-input" autocomplete="off" aria-label="Search site" placeholder="Search for" data-search-index="../search.json">
</form></li>
<li class="nav-item"><a class="external-link nav-link" href="https://github.com/mlr-org/mlr3tuning/" aria-label="GitHub"><span class="fa fab fa-github fa-lg"></span></a></li>
<li class="nav-item"><a class="external-link nav-link" href="https://lmmisld-lmu-stats-slds.srv.mwn.de/mlr_invite/"><span class="fa fa-comments"></span></a></li>
<li class="nav-item"><a class="external-link nav-link" href="https://stackoverflow.com/questions/tagged/mlr"><span class="fa fab fa-stack-overflow"></span></a></li>
<li class="nav-item"><a class="external-link nav-link" href="https://mlr-org.com/"><span class="fa fa-rss"></span></a></li>
<li class="nav-item dropdown">
  <button class="nav-link dropdown-toggle" type="button" id="dropdown-lightswitch" data-bs-toggle="dropdown" aria-expanded="false" aria-haspopup="true" aria-label="Light switch"><span class="fa fa-sun"></span></button>
  <ul class="dropdown-menu dropdown-menu-end" aria-labelledby="dropdown-lightswitch">
<li><button class="dropdown-item" data-bs-theme-value="light"><span class="fa fa-sun"></span> Light</button></li>
    <li><button class="dropdown-item" data-bs-theme-value="dark"><span class="fa fa-moon"></span> Dark</button></li>
    <li><button class="dropdown-item" data-bs-theme-value="auto"><span class="fa fa-adjust"></span> Auto</button></li>
  </ul>
</li>
      </ul>
</div>


  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="../logo.png" class="logo" alt=""><h1>Add a new Tuner</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/mlr-org/mlr3tuning/blob/main/vignettes/extending.Rmd" class="external-link"><code>vignettes/extending.Rmd</code></a></small>
      <div class="d-none name"><code>extending.Rmd</code></div>
    </div>

    
    
<div class="section level2">
<h2 id="adding-new-tuners">Adding new Tuners<a class="anchor" aria-label="anchor" href="#adding-new-tuners"></a>
</h2>
<p>In this vignette, we show how to implement a custom tuner for
<code>mlr3tuning</code>. The main task of a tuner is to iteratively
propose new hyperparameter configurations that we want to evaluate for a
given task, learner and validation strategy. The second task is to
decide which configuration should be returned as a tuning result -
usually it is the configuration that led to the best observed
performance value. If you want to implement your own tuner, you have to
implement an R6-Object that offers an <a href="#tuner-optimize"><code>.optimize</code></a> method that implements
the iterative proposal and you are free to implement <a href="#tuner-add-result"><code>.assign_result</code></a> to differ from
the before-mentioned default process of determining the result.</p>
<p>Before you start with the implementation make yourself familiar with
the main R6-Objects in <code>bbotk</code> (Black-Box Optimization
Toolkit). This package does not only provide basic black box
optimization algorithms and but also the objects that represent the
optimization problem (<code>OptimInstance</code>) and the log of all
evaluated configurations (<code>Archive</code>). d There are two ways to
implement a new tuner: a ) If your new tuner can be applied to any kind
of optimization problem it should be implemented as a
<code>Optimizer</code>. Any <code>Optimizer</code> can be easily
transformed to a <code>Tuner</code>. b) If the new custom tuner is only
usable for hyperparameter tuning, for example because it needs to access
the task, learner or resampling objects it should be directly
implemented in <code>mlr3tuning</code> as a <code>Tuner</code>.</p>
<div class="section level3">
<h3 id="adding-a-new-tuner">Adding a new Tuner<a class="anchor" aria-label="anchor" href="#adding-a-new-tuner"></a>
</h3>
<p>This is a summary of steps for adding a new tuner. The fifth step is
only required if the new tuner is added via <code>bbotk</code>.</p>
<ol style="list-style-type: decimal">
<li>Check the tuner does not already exist as a <a href="https://github.com/mlr-org/bbotk/tree/master/R" class="external-link"><code>Optimizer</code></a>
or <a href="https://github.com/mlr-org/mlr3tuning/tree/master/R" class="external-link"><code>Tuner</code></a>
in the GitHub repositories.</li>
<li>Use one of the existing optimizers / tuners as a <a href="#tuner-template">template</a>.</li>
<li>Overwrite the <a href="#tuner-optimize"><code>.optimize</code></a>
private method of the optimizer / tuner.</li>
<li>Optionally, overwrite the default <a href="#tuner-add-result"><code>.assign_result</code></a> private
method.</li>
<li>Use the <a href="#tuner-from-optimizer"><code>mlr3tuning::TunerBatchFromOptimizerBatch</code></a>
class to transform the <code>Optimizer</code> to a
<code>Tuner</code>.</li>
<li>Add <a href="#tuner-test">unit tests</a> for the tuner and
optionally for the optimizer.</li>
<li>Open a new pull request for the <a href="https://github.com/mlr-org/mlr3tuning/pulls" class="external-link"><code>Tuner</code></a>
and optionally a second one for the <a href="https://github.com/mlr-org/bbotk/pulls" class="external-link">`Optimizer</a>.</li>
</ol>
</div>
<div class="section level3">
<h3 id="tuner-template">Template<a class="anchor" aria-label="anchor" href="#tuner-template"></a>
</h3>
<p>If the new custom tuner is implemented via <code>bbotk</code>, use
one of the existing optimizer as a template e.g. <a href="https://github.com/mlr-org/bbotk/blob/master/R/OptimizerBatchRandomSearch.R" class="external-link"><code>bbotk::OptimizerRandomSearch</code></a>.
There are currently only two tuners that are not based on a
<code>Optimizer</code>: <a href="https://github.com/mlr-org/mlr3hyperband/blob/master/R/TunerBatchHyperband.R" class="external-link"><code>mlr3hyperband::TunerHyperband</code></a>
and <a href="https://github.com/mlr-org/mlr3tuning/blob/master/R/TunerBatchIrace.R" class="external-link"><code>mlr3tuning::TunerIrace</code></a>.
Both are rather complex but you can still use the documentation and
class structure as a template. The following steps are identical for
optimizers and tuners.</p>
<p>Rewrite the meta information in the documentation and create a new
class name. Scientific sources can be added in
<code>R/bibentries.R</code> which are added under <code>@source</code>
in the documentation. The example and dictionary sections of the
documentation are auto-generated based on the
<code>@templateVar id &lt;tuner_id&gt;</code>. Change the parameter set
of the optimizer / tuner and document them under
<code>@section Parameters</code>. Do not forget to change
<code>mlr_optimizers$add()</code> / <code>mlr_tuners$add()</code> in the
last line which adds the optimizer / tuner to the dictionary.</p>
</div>
<div class="section level3">
<h3 id="optimize-method">Optimize method<a class="anchor" aria-label="anchor" href="#optimize-method"></a>
</h3>
<p>The <code>$.optimize()</code> private method is the main part of the
tuner. It takes an instance, proposes new points and calls the
<code>$eval_batch()</code> method of the instance to evaluate them. Here
you can go two ways: Implement the iterative process yourself or call an
external optimization function that resides in another package.</p>
<div class="section level4">
<h4 id="writing-a-custom-iteration">Writing a custom iteration<a class="anchor" aria-label="anchor" href="#writing-a-custom-iteration"></a>
</h4>
<p>Usually, the proposal and evaluation is done in a
<code>repeat</code>-loop which you have to implement. Please consider
the following points:</p>
<ul>
<li>You can evaluate one or multiple points per iteration</li>
<li>You don’t have to care about termination, as
<code>$eval_batch()</code> won’t allow more evaluations then allowed by
the <code><a href="https://bbotk.mlr-org.com/reference/Terminator.html" class="external-link">bbotk::Terminator</a></code>. This implies, that code after the
<code>repeat</code>-loop will not be executed.</li>
<li>You don’t have to care about keeping track of the evaluations as
every evaluation is automatically stored in
<code>inst$archive</code>.</li>
<li>If you want to log additional information for each evaluation of the
<code>Objective</code> in the <code>Archive</code> you can simply add
columns to the <code>data.table</code> object that is passed to
<code>$eval_batch()</code>.</li>
</ul>
</div>
<div class="section level4">
<h4 id="calling-an-external-optimization-function">Calling an external optimization function<a class="anchor" aria-label="anchor" href="#calling-an-external-optimization-function"></a>
</h4>
<p>Optimization functions from external packages usually take an
objective function as an argument. In this case, you can pass
<code>inst$objective_function</code> which internally calls
<code>$eval_batch()</code>. Check out <a href="https://github.com/mlr-org/bbotk/blob/master/R/OptimizerBatchGenSA.R" class="external-link"><code>OptimizerGenSA</code></a>
for an example.</p>
</div>
</div>
<div class="section level3">
<h3 id="assign-result-method">Assign result method<a class="anchor" aria-label="anchor" href="#assign-result-method"></a>
</h3>
<p>The default <code>$.assign_result()</code> private method simply
obtains the best performing result from the archive. The default method
can be overwritten if the new tuner determines the result of the
optimization in a different way. The new function must call the
<code>$assign_result()</code> method of the instance to write the final
result to the instance. See <a href="https://github.com/mlr-org/mlr3tuning/blob/master/R/TunerBatchIrace.R" class="external-link"><code>mlr3tuning::TunerIrace</code></a>
for an implementation of <code>$.assign_result()</code>.</p>
</div>
<div class="section level3">
<h3 id="transform-optimizer-to-tuner">Transform optimizer to tuner<a class="anchor" aria-label="anchor" href="#transform-optimizer-to-tuner"></a>
</h3>
<p>This step is only needed if you implement via <code>bbotk</code>. The
<code><a href="../reference/TunerBatchFromOptimizerBatch.html">mlr3tuning::TunerBatchFromOptimizerBatch</a></code> class transforms a
<code>Optimizer</code> to a <code>Tuner</code>. Just add the
<code>Optimizer</code> to the <code>optimizer</code> field. See <a href="https://github.com/mlr-org/mlr3tuning/blob/master/R/TunerBatchRandomSearch.R" class="external-link"><code>mlr3tuning::TunerRandomSearch</code></a>
for an example.</p>
</div>
<div class="section level3">
<h3 id="add-unit-tests">Add unit tests<a class="anchor" aria-label="anchor" href="#add-unit-tests"></a>
</h3>
<p>The new custom tuner should be thoroughly tested with unit tests.
<code>Tuner</code>s can be tested with the <code>test_tuner()</code>
helper function. If you added the Tuner via a <code>Optimizer</code>,
you should additionally test the <code>Optimizer</code> with the
<code>test_optimizer()</code> helper function.</p>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc" aria-label="Table of contents"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p>Developed by Marc Becker, Michel Lang, Jakob Richter, Bernd Bischl, Daniel Schalk.</p>
</div>

<div class="pkgdown-footer-right">
  <p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.1.0.</p>
</div>

    </footer>
</div>





  </body>
</html>
